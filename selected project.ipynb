{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e7d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moham\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision.transforms as transforms \n",
    "from torch.utils.data import DataLoader ,SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf76efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CarPaleteDataset(Dataset):\n",
    "    globalIt = 0\n",
    "    dic = {}\n",
    "    def __init__(self , csv_file , root_dir , transform = None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir \n",
    "        self.transform = transform\n",
    "        self.freq = 0\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir , self.df.iloc[index , 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.df.iloc[index , 1]\n",
    "        if label in CarPaleteDataset.dic.keys():\n",
    "            self.freq += 1\n",
    "        else:\n",
    "            CarPaleteDataset.dic[label] = CarPaleteDataset.globalIt    \n",
    "            CarPaleteDataset.globalIt += 1\n",
    "            \n",
    "        y_label = torch.tensor(CarPaleteDataset.dic[label])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image, y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a18fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transformed = transforms.Compose([\n",
    "    transforms.Resize(size = (128,128)) , \n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_data = CarPaleteDataset(csv_file=r'C:\\Users\\Moham\\Desktop\\dataset\\selected\\train.csv' , root_dir=r\"C:\\Users\\Moham\\Desktop\\dataset\\selected\\train\" , \n",
    "                            transform=transformed)\n",
    "test_data = CarPaleteDataset(csv_file=r'C:\\Users\\Moham\\Desktop\\dataset\\selected\\val.csv',root_dir=r\"C:\\Users\\Moham\\Desktop\\dataset\\selected\\val\" , \n",
    "                            transform=transformed)\n",
    "\n",
    "samplerInd = np.random.choice(len(train_data) , 1000 , replace=False)\n",
    "sampler = SubsetRandomSampler(samplerInd)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_data , batch_size=64 , shuffle = True)\n",
    "test_loader = DataLoader(dataset = train_data , batch_size=64  , sampler=sampler)\n",
    "\n",
    "ss = 0\n",
    "for X,y in train_loader:\n",
    "    ss += y.shape[0]\n",
    "for X,y in test_loader:\n",
    "    pass\n",
    "#print(len(train_data.dic.keys()) , ss  , train_data.freq)\n",
    "\n",
    "def getInfo():\n",
    "    return train_loader , test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9ee578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingLoss= 7.664087897691971 ,trainingAcc= 0.161 |testLoss= 7.545524209737778 ,testAcc= 0.3\n",
      "trainingLoss= 7.495320955912272 ,trainingAcc= 0.372 |testLoss= 7.304140418767929 ,testAcc= 0.7\n",
      "trainingLoss= 6.881800645436996 ,trainingAcc= 2.765 |testLoss= 5.314274102449417 ,testAcc= 18.4\n",
      "trainingLoss= 3.3074609683110165 ,trainingAcc= 44.476 |testLoss= 1.080564547330141 ,testAcc= 79.8\n",
      "trainingLoss= 0.8270000106631181 ,trainingAcc= 83.322 |testLoss= 0.30629503913223743 ,testAcc= 92.7\n",
      "trainingLoss= 0.2807389352088555 ,trainingAcc= 93.475 |testLoss= 0.13356042187660933 ,testAcc= 96.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self , input_shape , hidden_units , output_shape):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels= input_shape , out_channels= hidden_units,kernel_size=3 , stride=1 , padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels= hidden_units , out_channels= hidden_units,kernel_size=3 , stride=1 , padding=1),\n",
    "        nn.ReLU(), \n",
    "        nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels= hidden_units , out_channels= hidden_units,kernel_size=3 , stride=1 , padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels= hidden_units , out_channels= hidden_units,kernel_size=3 , stride=1 , padding=1),\n",
    "        nn.ReLU(), \n",
    "        nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=hidden_units*32*32 , out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self , x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN(input_shape= 1 , hidden_units=10 , output_shape=2152)\n",
    "train_loader , test_loader = getInfo()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.parameters() , lr = 1e-4)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def trainingStep(model , train_loader , criterion , optimizer , device):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss , correct , samples = 0 , 0 , 0\n",
    "    \n",
    "    for x , y in train_loader:\n",
    "        x , y = x.to(device) , y.to(device)\n",
    "        yPred = model(x)\n",
    "        \n",
    "        loss = criterion(yPred , y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += (y == yPred.argmax(dim = 1)).sum()\n",
    "        samples += len(y)\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    acc = round(float(correct/samples)*100,3)\n",
    "    \n",
    "    return train_loss , acc\n",
    "\n",
    "def testingStep(model , test_loader , criterion , device):\n",
    "    \n",
    "    test_loss , correct , samples = 0 , 0 , 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for x , y in test_loader:\n",
    "\n",
    "            x , y = x.to(device) , y.to(device)\n",
    "            yPred = model(x)\n",
    "\n",
    "            loss = criterion(yPred , y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            correct += (y==yPred.argmax(dim = 1)).sum()\n",
    "            samples += len(y)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    acc = round(float(correct/samples)*100,3)\n",
    "    \n",
    "    return test_loss , acc\n",
    "\n",
    "trainingLosses , trainingAcc = [] , []\n",
    "testLosses , testAcc = [] , []\n",
    "\n",
    "for epoch in range(6):\n",
    "    \n",
    "    train_loss , train_acc = trainingStep(model , train_loader , criterion , optimizer , device)\n",
    "    test_loss , test_acc = testingStep(model , test_loader , criterion , device)\n",
    "    \n",
    "    trainingLosses.append(train_loss)\n",
    "    trainingAcc.append(train_acc)\n",
    "    testLosses.append(test_loss)\n",
    "    testAcc.append(test_acc)\n",
    "     \n",
    "    print(f'trainingLoss= {train_loss} ,trainingAcc= {train_acc} |testLoss= {test_loss} ,testAcc= {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa24401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea69564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a2b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e19e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
